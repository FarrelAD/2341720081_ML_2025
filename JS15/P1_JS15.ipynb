{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13733f1f",
   "metadata": {},
   "source": [
    "# 0. Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a7b136",
   "metadata": {},
   "source": [
    "# 1. Dataset Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f564ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(img_dir):\n",
    "    p = Path(img_dir)\n",
    "    img_list = []\n",
    "    for folder in p.glob(\"*\"):\n",
    "        label = folder.name\n",
    "        for file in folder.glob(\"*.jpg\"):\n",
    "            img = cv2.imread(str(file))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_list.append((img, label))\n",
    "    return img_list\n",
    "\n",
    "\n",
    "train_dir = \"/content/drive/MyDrive/FolderAnda/images/training/\"\n",
    "test_dir = \"/content/drive/MyDrive/FolderAnda/images/test\"\n",
    "\n",
    "train_img = load_dataset(train_dir)\n",
    "test_img = load_dataset(test_dir)\n",
    "\n",
    "print(f\"Jumlah data training: {len(train_img)}\")\n",
    "print(f\"Jumlah data testing: {len(test_img)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85665e",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e5b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, size=(256, 256)):\n",
    "    return cv2.resize(img, size)\n",
    "\n",
    "\n",
    "def label_encoder(label):\n",
    "    return 1 if label == \"day\" else 0\n",
    "\n",
    "\n",
    "def preprocess(img_list):\n",
    "    X = []\n",
    "    y = []\n",
    "    for img, label in img_list:\n",
    "        img_std = resize_image(img)\n",
    "        X.append(img_std)\n",
    "        y.append(label_encoder(label))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X_train_img, y_train = preprocess(train_img)\n",
    "X_test_img, y_test = preprocess(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde87e39",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog(X_imgs):\n",
    "    feats = []\n",
    "    for img in X_imgs:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        hog_feat = hog(\n",
    "            gray,\n",
    "            orientations=9,\n",
    "            pixels_per_cell=(8, 8),\n",
    "            cells_per_block=(2, 2),\n",
    "            block_norm=\"L2-Hys\",\n",
    "            visualize=False,\n",
    "            feature_vector=True,\n",
    "        )\n",
    "        feats.append(hog_feat)\n",
    "    return np.array(feats)\n",
    "\n",
    "\n",
    "X_train_feat = extract_hog(X_train_img)\n",
    "X_test_feat = extract_hog(X_test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da3326",
   "metadata": {},
   "source": [
    "# 4. Normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_feat)\n",
    "X_test_scaled = scaler.transform(X_test_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8f62d",
   "metadata": {},
   "source": [
    "# 5. Label Conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab9fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_val = np.array(y_val)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee85b15",
   "metadata": {},
   "source": [
    "# 6. Modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c96fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371842a6",
   "metadata": {},
   "source": [
    "# 7. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b602ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train, epochs=20, batch_size=32, validation_data=(X_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e28559",
   "metadata": {},
   "source": [
    "# 8. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Akurasi Test:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6467532",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Visualize training history\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc731edf",
   "metadata": {},
   "source": [
    "# 9. Saved the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6549819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save(\"day_night_model.h5\")\n",
    "print(\"✅ Model berhasil disimpan sebagai: day_night_model.h5\")\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"✅ Scaler berhasil disimpan sebagai: scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
